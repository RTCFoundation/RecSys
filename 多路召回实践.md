# 资讯推荐中多路召回实践

## 1. 召回服务框架介绍

![RecallFramework](/Users/menglingfeng/Documents/GitHub/RecSys/images/RecallFramework.jpg)

### 1.1 任务调度平台

这里主要介绍下比较主流的任务调度框架-airflow

airflow是一块开源的分布式任务调度框架，它将一个具有依赖关系的工作流，组装成一个有向无环图

特点：

1. 分布式任务调度：允许一个工作流的task在堕胎worker上同时执行
2. 可构建任务依赖：以有向无环图的方式构建任务依赖关系
3. task原子性：工作流上每个task都是原子可重试的，一个工作流某个环节的task失败，可自动或手动进行重试，不必从头开始任务

注：任务调度平台通常是大数据部或算法工程组的人联合开发，涉及数据、平台、算法、底层存储和监控等

![airflow](/Users/menglingfeng/Documents/GitHub/RecSys/images/airflow.jpg)

一个dag表示一个定时的工作流

示例：基于item_cf的任务调度

涉及任务

1. 抽取日志数据任务
2. item_cf计算任务（计算相似矩阵）

任务必须先抽取数据，后计算。因为存在先后依赖关系，所以必须设置这两个task依赖关系

### 1.2 向量服务平台

向量服务平台，也称为向量检索服务，其解决的问题是从海量向量数据中高精度、高性能地召回出与目标最相似的数据

向量服务平台的底层框架有

1. 基于量化的索引
2. 基于树的索引
3. 基于图的索引
4. 基于哈希的索引

这里主要介绍使用最多的基于树的索引

方法原理：搜索树思想，用超平面将高维空间分割成多个子空间，并把这些子空间以树型结构存储

算法实现：ANN搜索算法（faiss，Annoy，balltree）

![VectorService](/Users/menglingfeng/Documents/GitHub/RecSys/images/VectorService.jpg)

示例：

matrix_cf获取user_embedding和item_embedding

存入向量库中并加载到向量检索中提供服务



ANN算法-Balltree 构建原理

选择一个距离当前圆心最远的观测点i1和距离i1最远的观测点i2，将圆中所有离这两个点最近的观测点都赋给这两个簇的中心。然后计算每一个簇的中心点和包含所有其所属观测点的最小半径，不断递归

### 1.3 特征服务

特征服务实际上为一个存储用户特征和物料特征的存储平台

特点：

1. 存储的特征包含原始型和处理型
2. 存储的特征是实时更新的
3. 对外提供的服务是并发、高效、安全的
4. 分布式、可扩展性

示例：

用户点击历史特征

hist:[item2, item1]

当用户点击了item3，特征实时更新

Hist:[item3, item2, item1]

### 1.4 redis存储平台

redis存储平台是一个开源的、基于内存的数据结构存储器，用作数据库、缓存和消息中间件

特点：

1. C/S架构
2. 可分布式、可扩展性、高吞吐量

## 2. 资讯多路召回开发

### 2.1 特征工程

抽取特征并保存到redis数据库中

```python
# redis info
# db = 1 用户特征
# db = 2 文章特征
# db = 3 matrix_cf的文章相似矩阵
# db = 4 item_cf的文章相似矩阵
# db = 5 user_cf的用户相似矩阵
# db = 6 fm_i2i的文章相似矩阵
# db = 7 fm召回的文章隐向量
# db = 8 fm召回的用户隐向量
def save_redis(item, db = 1):
  redis_url = '127.0.0.1:6379/' + str(db)
  pool = redis.from_url(redis_url)
  try:
    for item in items:
      pool.set(item[0], item[1])
  except:
    traceback.print_exc()
```

```python
def get_item_feature():
  ds = pd.read_csv("./data/articles.csv")
  ds = ds.to_dict(orient = 'records')
  item_feature = []
  # (1336, {'article_id': 1336, 'category_id': 1, 'created_at_ts' : 1474330000, 'words_count' : 233})
  for d in ds:
    item_feature.append((d['article_id'], json.dumpes(d)))
  save_redis(item_feature, 2)
```

```python
def get_user_feature():
  ds = pd.read_csv("./data/click_log.csv")
  click_df = ds.sort_values('timestamp')
  #{100000:(4,13)}
  user_environment_region_dict = {}
  for info in zip(click_df['user_id'],
                 click_df['environment'], click_df['region']):
    user_environment_region_dict[info[0]] = (info[1], info[2])
    
  def make_item_time_pair(df):
    return list(zip(df['article_id'], df['timestamp']))
  
  # {100000, [(160417, 1507029570190), (5409, 1507029571478)]}
  user_item_time_df = click_df.groupby('user_id')[
    	'article_id', 'timestamp'].apply(
    	lambda x: make_item_time_pair(x)) \
  		.reset_index().rename(columns = {0: 'item_time_list'})
  
  user_item_time_dic = dict(
  	zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))
  
  user_feature = []
  for user, item_time_dict in user_item_time_dict.items():
    info = user_environment_region_dict[user]
    tmp = (str(user), json.dumps({
      'user_id': user, # 100000
      'hists': item_time_dict,
      'environment': info[0],
      'region': info[1]
    }))
    user_feature.append(tmp)
    
  save_redis(user_feature, 1)
```

### 2.2 Item_cf召回

ItemCF的主要思想：给用户推荐之前喜欢物品的相似物品

基于物品的协同过滤算法主要有三步：

1. 计算物品之间的相似度
2. 计算推荐结果
3. 惩罚热门物品/加入关联规则

物品相似度计算公式

wij  = 对物品i和物品j共同产生过行为的用户数/对物品i产生过行为的个数

可以对活跃用户和热门物品都进行惩罚

然后我们会基于关联规则对相似度权重进行加权

1. 考虑时间因素，两篇资讯点击时间相近权重大
2. 考虑资讯自身累呗因素，资讯类别相同，权重大

```python
# 根据点击时间获取用户的点击文章序列
# {user1:[(item1, time1), (itme2, time2),...], ...}
def get_user_item_time(click_df):
  click_df = click_df.sort_values('timestamp')
  def make_item_time_pair(df):
    return list(zip(df['article_id'], df['timestamp']))
  
  user_item_time_df = click_df.groupby('user_id')[
    'article_id', 'timestamp'].apply(
  	lambda x: make_itme_time_pair(x))\
  	.reset_index().rename(columns = {0: 'item_time_list'})
  
  user_item_time_dict = dict(
  	zip(user_time_time_df['user_id'], user_item_time_df['item_time_list']))
  return user_item_time_dict
```

```python
def item_cf_sim(user_item_time_dict, pool, cut_off = 20):
  # 定义一个缓存item信息的缓存区
  item_info = {}
  # 计算物品相似度
  i2i_sim = {}
  item_count = defaultdict(int)
  for user, item_time_list in tqdm(user_item_time_dict.item()):
    # 在基于商品的协同过滤优化的同时可以考虑时间因素
    for loc1, (i, i_click_time) in enumerate(item_time_list):
      item_cnt[i] += 1
      i2i_sim.setdefault(i, {})
      for loc2, (j, j_click_time) in enumerate(item_time_list):
        if i == j:
          continue
        # 点击时间权重，其中的参数可以调节。点击时间相近权重大
        click_time_weight = np.exp(
        0.7 ** np.abs(i_click_time - j_click_time))
        
        # 两篇文章的类别权重，其中类别相同权重越大
        item_i_info = item_info.get(i, None)
        if item_i_info is None:
          item_i_info = json.loads(pool.get(str(i)))
          item_info[i] = item_i_info
        item_j_info = item_info.get(j, None)
        if item_j_info is None:
          item_j_info = json.loads(pool.get(str(j)))
          item_info[j] = item_j_info
        type_weight = 1.0 if item_i_info['category_id'] == item_j_info['category_id'] else 0.7
        i2i_sim[i].setdefault(j, 0)
        
        # 考虑多种因素的权重计算最终的文章之间的相似度
        i2i_sim[i][j] += click_time_weight * type_wight/math.log(len(item_time_list) + 1)
  print("item_info get nums: ", len(item_info))
  i2i_sim_ = i2i_sim.copy()
  for i, related_items in i2i_sim.items():
    tmp = {}
    for j, wij in related_items.items():
      tmp[j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])
    i2i_sim_[i] = sorted(
    	tmp.items(), key = lambda _: _[1], reverse = True)[:cut_off]
  # 将得到的相似性矩阵保存到redis
  save_redis(i2i_sim_, db = 4)
```

```python
# item_cf测试
click_df = pd.read_csv("./data/click_log.csv")
print("user history gen ...")
user_item_time_dict = get_user_item_time(click_df)

redis_url = "127.0.0.1:6379/2"
pool = redis.from_url(redis_url)
item_cf_sim(user_item_time_dict, pool. cut_off = 200)
```

### 2.3 user_cf召回

主要思想：给用户推荐与其相似的用户喜欢的物品，模式是u2u2i

用户协同过滤算法主要也有三步

1. 计算用户之间的相似度
2. 计算推荐结果
3. 惩罚热门物品/加入关联规则

```python
# 根据时间获取商品被点击的用户序列
# {item: [(user1, time1), (user2, time2), ...], ...}
def get_item_user_time_dict(click_df):
  def make_user_time_pair(df):
    return list(zip(df['user_id'], df['timestamp']))
  click_df = click_df.sort_values('timestamp')
  item_user_time_df = click_df.groupby('article_id')[
    'user_id', 'time_stamp'].apply(lambda x : make_user_time_pair(x)) \
  	.reset_index().rename(columns = {0: 'user_time_list'})
  item_user_time_dict = dict(zip(item_user_time_df['article_id'],
                                item_user_time_df['user_time_list']))
  return item_user_time_dict
```

```python
def user_cf_sim(item_user_time_dict, pool, cut_off = 20):
  # 定义一个缓存user信息的缓存区
  user_info = {}
  # 计算用户的相似度
  u2u_sim = {}
  user_cnt = defaultdict(int)
  for item, user_time_list in tqdm(item_user_time_dict.items()):
    for u, click_time in user_time_list:
      user_cnt[u] += 1
      u2u_sim.setdefault(u, {})
      for v, click_time in user_time_list:
        u2u_sim[u].setdefault(v, 0)
        if u == v:
          continue
          
        # 用户平均活跃度作为活跃度的权重，这里的公式可以改善
        # 两篇文章的类别权重，其中类别相同权重越大
        user_u_info = user_info.get(u, None)
        if user_u_info is None:
          user_u_info = json.loads(pool.get(str(u)))
          user_info[u] = user_u_info
        if user_v_info is None:
          user_v_info = json.loads(pool.get(str(v)))
          user_info[v] = user_v_info
        activate_weight = 0.1 * 0.5 * (len(user_v_info['hists']) +
                                      len(user_u_info['hists']))
        u2u_sim[u][v] += activate_weight / math.log(
        				len(user_time_list) + 1)
        
  u2u_sim_ = u2u_sim.copy()
  for u, related_users in u2u_sim.items():
    tmp = {}
    for v, wij in related_users.items():
      tmp[v] = wij / math.sqrt(user_cnt[u] * user_cnt[v])
    u2u_sim_[u] = sorted(
    	tmp.items(), key = lambda _: _[1], reverse = True)[:cut_off]
  
  # 将得到的相似性矩阵保存到本地
  save_redis(u2u_sim_, db = 5)  
```

```python
# 测试
click_df= pd.read_csv("./data/click_log.csv")
print('item history gen ...')
item_user_time_dict = get_time_user_time_dict(click_df)

redis_url = '127.0.0.1:6379/1'
pool = redis.from_url(redis_url)
user_ct_sim(item_user_time_dict, pool, cut_off = 20)
```

### 2.4 MatrixCF算法召回

```python
# 向量检索相似度计算
# top K值得的每个item，faiss搜索后返回最相似的top K个Item
def embedding_sim(item_emb_file, cut_off = 20):
  # 文章索引与文章id的字典映射
  item_embedding = read_embedding_file(item_emb_file)
  item_idx_2_rawid_dict= {}
  item_emb_np = []
  for i, (k, v) in enumerate(item_embedding.items()):
    item_idx_2_rawid_dic[i] = k
    item_emb_np.append(v)
  
  item_emb_np = np.asarray(item_emb_np)
  item_emb_np = item_emb_np /np.linalg.norm(
  	item_emb_np, axis = 1, keepdims = True)
  
  # 建立faiss/BallTree索引
  item_tree = neighbors.BallTree(item_emb_np, leaf_size = 40)
  # 相似度查询，给每个索引位置上的向量返回top K个item以及相似度
  sim, idx = item_tree.query(item_emb_np, cut_off) # 返回的是列表
  
  # 将向量检索的结果保存成原始id的对应关系
  item_emb_sim_dict = {}
  for target_idx, sim_value_list, rele_idx_list in tqdm(
  		zip(range(len(item_emb_np), sim, idx))):
    target_raw_id = item_idx_2_rawid_dict[target_idx]
    sim_tmp = {}
    # 从1开始是为了去掉商品本身，所以最终获得的相似商品只有top K-1
    for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]):
      rele_raw_id = item_idx_2_rawid_dict[rele_idx]
      sim_tmp[rele_raw_id] = sim_value
    item_emb_sim_dict[target_raw_id] = sorted(
    	sim_tmp.items(), key = lambda _: _[1], reverse = True)[:cut_off]
  
  item_simi_tuple = [(_, json.dumps(v)) for _, v in item_emb_sim_dict.items()]
  save_redis(item_simi_tuple, db = 3)
```

### 2.5 FM算法召回

FM召回，英文全称是“Factorization Machine”，是一种基于矩阵分解的机器学习算法，是为了解决大规模稀疏矩阵中特征组合问题

基于FM召回算法有三步

1. 初始化线性部分LR的权重W和交叉部分的隐向量权重V
2. 基于计算公式，分别求出线性部分的输出和交叉部分的输出
3. 综合两种输出获得预估值，然后交叉熵loss，梯度更新权重W和V，最终获得每个特种的隐向量权重V

### 2.6 召回部署模块



## 3. 资讯召回推荐线上模拟

## 4. 总结